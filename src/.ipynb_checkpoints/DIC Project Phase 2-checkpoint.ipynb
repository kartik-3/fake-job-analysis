{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20e45d1",
   "metadata": {},
   "source": [
    "# ANALYSIZING FAKE JOB POSTINGS\n",
    "# BY - KARTIKSE & SHALINIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b68df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2a2cb",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c1b7bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fake_job_postings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfake_job_postings.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fake_job_postings.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"fake_job_postings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae6c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31517b3",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3eafc",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 1 - Removing blanks from requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8feb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data[\"requirements\"].notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee45d050",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0222b0d4",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 2 - Changing blank values to \"Not Provided\" in all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155aba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna('not-provided', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5494a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd6fce7",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 3 - Removing \"Other\" from employment_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.employment_type != \"Other\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec28ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eb4b50",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 4 - Split location into Country, State, and City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de344778",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"location_country\", \"location_state_temp\"]] = data.location.str.split(\",\", expand = True, n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659865f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"location_state\", \"location_city\"]] = data.location_state_temp.str.split(\",\", expand = True, n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389011c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"location_state_temp\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71249792",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"location\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00c597",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459950fe",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 5 - Split salary range column into minimum salary and maximum salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe13fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"salary_min\", \"salary_max\"]] = data.salary_range.str.split(\"-\", expand = True, n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d6d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"salary_range\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1a06f",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 6 - Replace blanks/not-provided salaries with 0 for min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbfceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['salary_min'] = data['salary_min'].replace('not' ,'0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db784b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['salary_max'] = data['salary_max'].replace('provided' ,'0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba448889",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 7 - Converting string salaries to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.salary_min = pd.to_numeric(data.salary_min, errors='coerce')\n",
    "data.salary_max = pd.to_numeric(data.salary_max, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f3cec",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 8 - Remove special characters from strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39900064",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 9 - Remove extra white space characters from start and end of string columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada327da",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 10 - Replace uppercase characters with lowercase characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2897246",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = [\"title\", \"department\", \"company_profile\", \"description\", \"requirements\", \"benefits\", \"employment_type\", \"required_experience\", \"required_education\", \"industry\", \"function\", \"location_country\", \"location_state\", \"location_city\"]\n",
    "\n",
    "for col in text_columns:\n",
    "    #Step 8 - Remove special characters from strings\n",
    "    data[col] = data[col].str.replace(r\"[^0-9a-zA-Z]+\", \" \")\n",
    "    #Step 9 - Remove extra white space characters from start and end of string columns\n",
    "    data[col] = data[col].str.strip()\n",
    "    #Step 10 - Replace uppercase characters with lowercase characters\n",
    "    data[col] = data[col].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25e193",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 11 - Remove numbers from locations - country, state, and city\n",
    "\n",
    "### Data Cleaning Step 12 - Removing locations which don't have country, state, or city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3503e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_cols = [\"location_country\", \"location_state\", \"location_city\"]\n",
    "for col in location_cols:\n",
    "    #Step 11 - Remove numbers from locations - country, state, and city\n",
    "    data[col] = data[col].str.replace('\\d+', '')\n",
    "    #Step 12 - Removing locations which don't have country, state, or city\n",
    "    data = data[(data[col] != \"\") & (data[col] != \" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aac3fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a43dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52354507",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 14 - Convert Data Type of Real/Fraud from int to Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f71ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"fraudulent\"] = data[\"fraudulent\"].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f44e03",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b0a5b8",
   "metadata": {},
   "source": [
    "### EDA 1 - Finding counts of values for every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d051c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = {}\n",
    "all_cols = list(data.columns.values)\n",
    "\n",
    "for col in all_cols:\n",
    "    print(col.upper())\n",
    "    print()\n",
    "    counts[col] = data[col].value_counts()\n",
    "    print(counts[col])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4af7f1",
   "metadata": {},
   "source": [
    "### EDA 2 - Finding ratio of \"not provided\" with \"provided\" for every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_provided_counts, provided_counts, total = {}, {}, 12372\n",
    "for col in counts:\n",
    "    if 'not provided' in counts[col]:\n",
    "        not_provided_counts[col] = counts[col][\"not provided\"]\n",
    "        provided_counts[col] = total - counts[col][\"not provided\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e353bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(not_provided_counts)), list(not_provided_counts.values()), align='center', color=['maroon'], label=\"not provided\")\n",
    "plt.bar(range(len(provided_counts)), list(provided_counts.values()), bottom=list(not_provided_counts.values()), align='center', color=['green'], label=\"provided\")\n",
    "plt.xticks(range(len(not_provided_counts)), list(not_provided_counts.keys()), rotation=90)\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "font1 = {'family':'serif','color':'brown','size':18}\n",
    "\n",
    "plt.ylabel(\"Counts\", fontdict = font1)\n",
    "plt.xlabel(\"Features\", fontdict = font1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98f731",
   "metadata": {},
   "source": [
    "### EDA 3 - Analysing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f428d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ab1752",
   "metadata": {},
   "source": [
    "### POST EDA DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c41ec6f",
   "metadata": {},
   "source": [
    "### Data Cleaning Step 13 - After feature analysis, drop unnecessary features - has_company_logo, has_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ece58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_cols = [\"has_company_logo\", \"has_questions\"]\n",
    "for col in unnecessary_cols:\n",
    "    data = data.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192dc4a",
   "metadata": {},
   "source": [
    "### EDA 4 - Division based on location_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a45345",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, loc_countries = 0, {}\n",
    "for c in counts[\"location_country\"].index:\n",
    "    if c != \"not provided\":\n",
    "        loc_countries[c] = counts[\"location_country\"][c]\n",
    "        i += 1\n",
    "    if i == 14: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6442d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(loc_countries)), loc_countries.values(), align='center', color=['purple'])\n",
    "plt.xticks(range(len(loc_countries)), list(loc_countries.keys()), rotation=90)\n",
    "\n",
    "plt.ylabel(\"Counts\", fontdict = font1)\n",
    "plt.xlabel(\"Countries\", fontdict = font1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ba2653",
   "metadata": {},
   "source": [
    "### EDA 5 - Finding ratio of Real vs Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a28fb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts[\"fraudulent\"].plot.pie(labels=[\"real\", \"fraud\"], autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdec31a",
   "metadata": {},
   "source": [
    "### EDA 6 - Minimum of salary_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ac1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_of_salary_min = data[\"salary_min\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_of_salary_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b402b",
   "metadata": {},
   "source": [
    "### EDA 7 - Maximum of salary_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908c4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_of_salary_min = data[\"salary_min\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_of_salary_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d809b",
   "metadata": {},
   "source": [
    "### EDA 8 - Mean of salary_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdddbb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_salary_min = data[\"salary_min\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_salary_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b443a883",
   "metadata": {},
   "source": [
    "### EDA 9 - Minimum of salary_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e15d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_of_salary_max = data[\"salary_max\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bcd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_of_salary_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e35c705",
   "metadata": {},
   "source": [
    "### EDA 10 - Maximum of salary_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4417dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_of_salary_max = data[\"salary_max\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d6694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maximum_of_salary_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c44fc6",
   "metadata": {},
   "source": [
    "### EDA 11 - Mean of salary_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb41f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_salary_max = data[\"salary_max\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_salary_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e94aa65",
   "metadata": {},
   "source": [
    "### EDA 12 - Division of required_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc041f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"required_experience\"].value_counts().plot(kind=\"pie\", autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2909884",
   "metadata": {},
   "source": [
    "### EDA 13 - Division of required_education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data[\"required_education\"].value_counts().plot(kind=\"bar\", color=\"darkblue\")\n",
    "ax.set_xlabel(\"Required Education\", fontdict = font1)\n",
    "ax.set_ylabel(\"Counts\", fontdict = font1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbc329",
   "metadata": {},
   "source": [
    "### EDA 14 - Division of employment_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d738b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data[\"employment_type\"].value_counts().plot(kind=\"line\", color=\"cyan\")\n",
    "ax.set_xlabel(\"Employment Type\", fontdict = font1)\n",
    "ax.set_ylabel(\"Counts\", fontdict = font1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f22a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d7669",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined['text'] = data['title']+' '+data['company_profile']+' '+data['description']+' '+data['requirements']+' '+data['benefits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87131022",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined['fraudulent'] = data['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b096de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d47f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_jobs_text = data_combined[data_combined.fraudulent == True].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_jobs_text = data_combined[data_combined.fraudulent == False].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a42dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_jobs_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300686bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_jobs_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "from wordcloud import WordCloud\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix, classification_report, confusion_matrix, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad37f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f31006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,14))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e2612",
   "metadata": {},
   "source": [
    "## Word Cloud - Fake Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dab79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_fake_jobs = WordCloud(min_font_size = 3, width = 1600, height = 800, stopwords = STOP_WORDS).generate(str(\" \".join(fraud_jobs_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c689f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(wc_fake_jobs, interpolation=\"bilinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac742124",
   "metadata": {},
   "source": [
    "## Word Cloud - Real Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90129d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_real_jobs = WordCloud(min_font_size = 3, width = 1600, height = 800, stopwords = STOP_WORDS).generate(str(\" \".join(real_jobs_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8850a434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(wc_real_jobs, interpolation=\"bilinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07134465",
   "metadata": {},
   "source": [
    "## Finding punctuations and stopwords to remove them from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13fd6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74369dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674eb715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d55a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = English()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c3d404",
   "metadata": {},
   "source": [
    "## Defining a tokenizer, lemmatizing all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32269f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(sentence):\n",
    "    # Creating our token object\n",
    "    tokens = parser(sentence)\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    tokens = [ word.lower_ for word in tokens ]\n",
    "    # Removing stop words\n",
    "    tokens = [ word for word in tokens if word not in stopwords and word not in punctuations ]\n",
    "    # return a preprocessed list of tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b110a7d",
   "metadata": {},
   "source": [
    "## Model 1 - K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a12617b",
   "metadata": {},
   "source": [
    "## Encoding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d83d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "dc_text = le.fit_transform(data_combined.text)\n",
    "dc_fraud = le.fit_transform(data_combined.fraudulent)\n",
    "\n",
    "transformed_features = list(zip(dc_text, dc_fraud))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7867ad7b",
   "metadata": {},
   "source": [
    "## Splitting data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50028241",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(transformed_features, dc_fraud, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f9875",
   "metadata": {},
   "source": [
    "## Creating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b2cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4876f",
   "metadata": {},
   "source": [
    "## Classification Report for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88688646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the classifier\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42ee65",
   "metadata": {},
   "source": [
    "## Confusion Matrix for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96278f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, X_test, y_test, cmap='Blues', values_format=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac7dc1",
   "metadata": {},
   "source": [
    "## ROC Curve for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c144097",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "plt.plot(lr_recall, lr_precision, marker='.', label='KNN')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b53bc7",
   "metadata": {},
   "source": [
    "## Spliting the data into test and train data and creating our predictor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a6094",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_combined.text, data_combined.fraudulent, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe08972",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Cleaning Text\n",
    "        return [text.strip().lower() for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a7936",
   "metadata": {},
   "source": [
    "## Model 2 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a55081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our bag of words\n",
    "vector = CountVectorizer(tokenizer = tokenizer, ngram_range=(1,2))\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172c705",
   "metadata": {},
   "source": [
    "## Creating a pipeline for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49726aee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(class_weight = 'balanced')\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vector),\n",
    "                 ('classifier', clf)])\n",
    "\n",
    "# fitting our model.\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a056e8",
   "metadata": {},
   "source": [
    "## Classification report for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78640e2c",
   "metadata": {},
   "source": [
    "## Confusion Matrix for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c233d35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(pipe, X_test, y_test, cmap='Blues', values_format=' ')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325c090",
   "metadata": {},
   "source": [
    "## ROC Curve for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "plt.plot(lr_recall, lr_precision, marker='.', label='Logistic Regression')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20cfed",
   "metadata": {},
   "source": [
    "## Model 3 -  Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a9ffb3",
   "metadata": {},
   "source": [
    "## Create a pipeline using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd28b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create pipeline using Bag of Words\n",
    "\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', CountVectorizer(tokenizer = tokenizer, ngram_range=(1,3))),\n",
    "                 ('classifier', SVC())])\n",
    "\n",
    "#Training the model.\n",
    "pipe.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c25908",
   "metadata": {},
   "source": [
    "## Classification report for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df588a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting with a test dataset\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"Classification Report\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74571aa",
   "metadata": {},
   "source": [
    "## Confusion Matrix for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0383588",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(pipe, X_test, y_test, cmap='Blues', values_format=' ')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8db4f5",
   "metadata": {},
   "source": [
    "## ROC Curve for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d3d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "plt.plot(lr_recall, lr_precision, marker='.', label='Support Vector Machine|')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9daf50",
   "metadata": {},
   "source": [
    "## Model 4 - Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2e80a",
   "metadata": {},
   "source": [
    "## Create a pipeline for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1ac92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(class_weight = 'balanced')\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vector),\n",
    "                 ('classifier', clf)])\n",
    "\n",
    "# fitting our model.\n",
    "pipe.fit(X_train,y_train)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b62373d",
   "metadata": {},
   "source": [
    "## Classification report for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14f652",
   "metadata": {},
   "source": [
    "## Confusion Matrix for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8923d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(pipe, X_test, y_test, cmap='Blues', values_format=' ')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f85564a",
   "metadata": {},
   "source": [
    "## ROC Curve for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32462460",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "plt.plot(lr_recall, lr_precision, marker='.', label='Decision Tree')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e638fe38",
   "metadata": {},
   "source": [
    "## Model 5 - XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f637d",
   "metadata": {},
   "source": [
    "## Creating a pipeline for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d92373",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(class_weight = 'balanced')\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vector),\n",
    "                 ('classifier', clf)])\n",
    "\n",
    "# fitting our model.\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54414944",
   "metadata": {},
   "source": [
    "## Classification report for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42555c",
   "metadata": {},
   "source": [
    "## Confusion Matrix for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2a418",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(pipe, X_test, y_test, cmap='Blues', values_format=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fecd36",
   "metadata": {},
   "source": [
    "## ROC Curve for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "plt.plot(lr_recall, lr_precision, marker='.', label='XGBoost')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
